{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import datasetPlt as dataset\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n",
    "correct_sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5\n",
    "num_filters1 = 16\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 3\n",
    "num_filters2 = 32\n",
    "\n",
    "# Convolutional Layer 3.\n",
    "filter_size3 = 3\n",
    "num_filters3 = 32\n",
    "\n",
    "# Convolutional Layer 4.\n",
    "filter_size3 = 4\n",
    "num_filters3 = 8\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128            \n",
    "\n",
    "num_channels = 3\n",
    "img_size = 64\n",
    "\n",
    "img_size_flat = img_size * img_size * num_channels\n",
    "\n",
    "img_shape = ( img_size, img_size)\n",
    "\n",
    "\n",
    "classes = ['Apple_Apple_scab',\n",
    "           'Apple_Black_rot','Apple_healthy','Apple_Cedar_apple_rust','Blueberry_healthy','Cherry_healthy',\n",
    "           'Cherry_Powdery_mildew','Corn_Cercospora_leaf_spot Gray_leaf_spot','Corn_Common_rust','Corn_Northern_Leaf_Blight',\n",
    "           'Corn_healthy','Grape_Black_rot','Grape_Esca_(Black_Measles)','Grape_healthy','Grape_Leaf_blight',\n",
    "           'Orange_Haunglongbing','Peach_Bacterial_spot','Pepper_bell_Bacterial_spot','Pepper_bell_healthy',\n",
    "           'Peach_healthy','Potato_Early_blight','Potato_healthy','Potato_Late_blight','Raspberry_healthy',\n",
    "           'Soybean_healthy','Squash_Powdery_mildew','Strawberry_healthy','Strawberry_Leaf_scorch',\n",
    "           'Tomato_Bacterial_spot','Tomato_Tomato_Yellow_Leaf_Curl_Virus','Tomato_Tomato_mosaic_virus','Tomato_Target_Spot',\n",
    "           'Tomato_Early_blight','Tomato_Spider_mites_Two-spotted_spider_mite','Tomato_Septoria_leaf_spot',\n",
    "           'Tomato_Leaf_Mold','Tomato_Late_blight','Tomato_healthy']\n",
    "\n",
    "num_classes = len(classes)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "validation_size = .16\n",
    "\n",
    "\n",
    "early_stopping = None\n",
    "\n",
    "train_path = 'C:/Users/Saurabh/Desktop/Train'\n",
    "test_path = 'plnt_villa/test'\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Reading training images\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "7589\n"
     ]
    }
   ],
   "source": [
    "data = dataset.read_train_sets(train_path, img_size, classes, validation_size=validation_size)\n",
    "\n",
    "\n",
    "#cv2.imshow('img', test_images[0])\n",
    "#cv2.waitKey(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t6375\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              \n",
    "                   num_input_channels, \n",
    "                   filter_size,        \n",
    "                   num_filters,        \n",
    "                   use_pooling=True):\n",
    "\n",
    "   \n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "   \n",
    "    weights = new_weights(shape=shape)\n",
    "\n",
    "   \n",
    "    biases = new_biases(length=num_filters)\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "    \n",
    "    \n",
    "\n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer): \n",
    "\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input,          \n",
    "                 num_inputs,     \n",
    "                 num_outputs,    \n",
    "                 use_relu=True,\n",
    "                 drop_out = True): \n",
    "\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    if drop_out:\n",
    "        layer = tf.nn.dropout(layer , 0.60)\n",
    "\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 32, 32, 16) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)\n",
    "layer_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 16, 16, 32) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2, weights_conv2 = \\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)\n",
    "layer_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 16, 16, 8) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv3, weights_conv3 = \\\n",
    "    new_conv_layer(input=layer_conv2,\n",
    "                   num_input_channels=num_filters2,\n",
    "                   filter_size=filter_size3,\n",
    "                   num_filters=num_filters3,\n",
    "                   use_pooling=False)\n",
    "layer_conv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv3)\n",
    "layer_flat\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_3:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True,\n",
    "                         drop_out = True)\n",
    "layer_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_4:0' shape=(?, 38) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False,\n",
    "                         drop_out = False)\n",
    "layer_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-a7125de2e7ab>:2: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMax_1:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "y_pred\n",
    "y_pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc2,labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-5).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "#session run\n",
    "session.run(tf.initialize_all_variables())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(epoch, feed_dict_train, feed_dict_validate, val_loss, train_loss):\n",
    " \n",
    "\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "    val_acc = session.run(accuracy, feed_dict=feed_dict_validate)\n",
    "    msg = \"Epoch {0} - T_A: {1:>6.1%}, V_A: {2:>6.1%}, Validation Loss: {3:.3f}, train_loss : {4:.3f}\"\n",
    "    print(msg.format(epoch + 1, acc, val_acc, val_loss, train_loss))\n",
    "    return epoch + 1, acc, val_acc, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_iterations = 0\n",
    "\n",
    "\n",
    "def optimize(num_iterations):\n",
    "\n",
    "    \n",
    "    global total_iterations\n",
    "    # time-usage\n",
    "    start_time = time.time()\n",
    "    \n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = 0\n",
    "\n",
    "    for i in range(total_iterations, total_iterations + num_iterations):\n",
    "\n",
    "        x_batch, y_true_batch, _, cls_batch = data.train.next_batch(train_batch_size)\n",
    "        x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.next_batch(train_batch_size)\n",
    "\n",
    "    \n",
    "        x_batch = x_batch.reshape(train_batch_size, img_size_flat)\n",
    "        x_valid_batch = x_valid_batch.reshape(train_batch_size, img_size_flat)\n",
    "\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "        \n",
    "        feed_dict_validate = {x: x_valid_batch,\n",
    "                              y_true: y_valid_batch}\n",
    "\n",
    "    \n",
    "        #print( \"{}  \\100 \".format(i) ,end='\\r')\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        if i%5 == 0: \n",
    "            val_loss = session.run(cost, feed_dict=feed_dict_validate)\n",
    "            train_loss = session.run(cost, feed_dict=feed_dict_train)\n",
    "            \n",
    "            epoch = total_iterations\n",
    "          \n",
    "            epoch, ta, va, vl = print_progress(epoch, feed_dict_train, feed_dict_validate, val_loss, train_loss)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            if early_stopping:    \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience = 0\n",
    "                else:\n",
    "                    patience += 1\n",
    "\n",
    "                if patience == early_stopping:\n",
    "                    break\n",
    "            total_iterations += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    print(\"Time elapsed: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_test_accuracy():\n",
    "    \n",
    "    num_test = len(data.valid.images)\n",
    "\n",
    "    correct_sum = 0\n",
    "    \n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        j = min(i + batch_size, num_test)\n",
    "        \n",
    "        images = data.valid.images[i:j, :].reshape(j-i, img_size_flat)\n",
    "        \n",
    "       # print(j-i)\n",
    "    \n",
    "        labels = data.valid.labels[i:j, :]\n",
    "\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "        \n",
    "        \n",
    "        \n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "        i = j\n",
    "        \n",
    "    cls_true = np.array(data.valid.cls)\n",
    "    cls_pred = np.array([classes[x] for x in cls_pred]) \n",
    "\n",
    "    \n",
    "    correct = (cls_true == cls_pred)\n",
    "\n",
    "  \n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Epoch 1 - T_A:   3.1%, V_A:   0.0%, Validation Loss: 3.639, train_loss : 3.631\n",
      "Time elapsed: 0:00:07\n",
      "INFO:tensorflow:Restoring parameters from model5.ckpt\n"
     ]
    }
   ],
   "source": [
    "print ( \"start\")\n",
    "optimize(num_iterations=1) \n",
    "\n",
    "saver.restore(session,'model5.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 61.4% (745 / 1214)\n",
      "Epoch 2 - T_A:  59.4%, V_A:  50.0%, Validation Loss: 1.566, train_loss : 1.592\n",
      "Epoch 3 - T_A:  68.8%, V_A:  81.2%, Validation Loss: 1.005, train_loss : 0.911\n",
      "Epoch 4 - T_A:  62.5%, V_A:  75.0%, Validation Loss: 1.272, train_loss : 1.170\n",
      "Epoch 5 - T_A:  71.9%, V_A:  75.0%, Validation Loss: 0.962, train_loss : 1.266\n",
      "Time elapsed: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()\n",
    "optimize(num_iterations=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 61.0% (741 / 1214)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_path = 'C:/Users/Saurabh/Desktop/Train/Cherry_healthy/CH (55).jpg'\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (64,64), cv2.INTER_LINEAR)\n",
    "\n",
    "img = img.astype('float32')\n",
    "img = img / 255\n",
    "\n",
    "img = img.reshape( -1 , img_size_flat)\n",
    "\n",
    "\n",
    "feed_dict = {x: img}\n",
    "cls_pred = session.run(y_pred_cls, feed_dict = feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cherry_healthy\n"
     ]
    }
   ],
   "source": [
    "print( classes[int(cls_pred)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
